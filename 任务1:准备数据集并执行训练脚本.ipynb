{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5895fe08",
   "metadata": {},
   "source": [
    "#  任务1:准备数据集并执行训练脚本\n",
    "\n",
    "## 职业能力目标：\n",
    "\n",
    "- 学习处理数据集\n",
    "\n",
    "- 了解预训练模型的使用\n",
    "\n",
    "- 了解模型训练过程\n",
    "\n",
    "## 任务描述\n",
    "\n",
    "- 实验环境准备\n",
    "\n",
    "- 数据集准备\n",
    "\n",
    "- 运行代码进行模型训练\n",
    "\n",
    "- 使用已训练好的模型进行物体识别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b73467",
   "metadata": {},
   "source": [
    "## 知识储备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fddd29",
   "metadata": {},
   "source": [
    "## 1 模型微调\n",
    "### 1.1模型微调概念\n",
    "- 模型微调是指将新数据集加入预训练过的模型进行训练，并使参数适应新数据集的过程。通常需要有一个初始化的模型参数文件。不同于在训练一个新的网络的过程中，模型的参数都被随机初始化。而微调在已经训练好的参数的基础上，根据分类识别任务进行特定的参数调整和训练。普通预训练模型的特点是用了大型数据集做训练，已经具备了提取浅层基础特征和深层抽象特征的能力。\n",
    "\n",
    "### 1.2适用情况\n",
    "- 微调训练可以大大提升训练效率，减少时间和计算资源。在遇到以下情况时可以考虑进行微调：\n",
    "  - 1）数据集和预训练模型的数据集相似，但数据量小\n",
    "  - 2）自己搭建或者使用的CNN模型正确率低\n",
    "  - 3）计算资源太少\n",
    "- 比如在一些特定领域的识别分类中，个人不容易获取大量的数据。在这种情况下重新训练一个新的网络是比较复杂的，而且参数不好调整，数据量也不够，因此微调就是一个比较理想的选择。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23eef82",
   "metadata": {},
   "source": [
    "## 2 训练集和测试集\n",
    "### 2.1 机器学习的流程\n",
    "  - 1）使用大量和任务相关的数据集来训练模型\n",
    "  - 2）通过模型在数据集上的误差不断迭代训练模型，得到对数据集拟合合理的模型\n",
    "  - 3）将训练好调整好的模型应用到真实的场景中\n",
    "  \n",
    "### 2.2 机器学习的目的与实现 \n",
    "- 训练模型的目标是提高训练后的模型在真实数据上预测准确率。通常把模型在真实环境中的误差叫做泛化误差，最终的目的是希望训练好的模型泛化误差越低越好。\n",
    "- 在训练开始之前，要先将数据分割成两部分：训练集和测试集。这样就可以使用训练集的数据来训练模型，然后用测试集上的误差作为最终模型在应对现实场景中的泛化误差。\n",
    "- 有了测试集，当要验证模型的最终效果时，只需将训练好的模型在测试集上计算误差，即可认为此误差即为泛化误差的近似值，可以通过比较训练好的模型在测试集上的误差大小来评估模型的泛化能力。  \n",
    "  \n",
    "### 2.3 注意事项\n",
    "  - 1）请勿使用测试集来调整训练参数，这相当于将测试集当成训练集来使用，并不能降低模型在真实场景下的泛化误差。将测试集用于调整训练参数相当于学生在考试之前就拿到了考题，导致此次考试成绩高的学生未必是真正掌握更多知识的学生。\n",
    "  - 2）在划分之前需要让样本顺序随机化，以保证训练集和测试集中不同类别标签的样本平衡。样本不平衡指数据集中、不同类别标签出现频率差距大，训练样本不平衡将影响模型的预测效果。由于测试集作为对泛化误差的近似，所以训练好模型，最后在测试集上近似估计模型的泛化能力。此时假设有两个不同的机器学习模型，犹豫不决的时候，可以通过训练两个模型，然后对比他们在测试数据上的泛化误差，选择泛化能力强的模型。\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd242e11",
   "metadata": {},
   "source": [
    "## 3 深度学习与框架\n",
    "### 3.1深度学习（Deep Learning）\n",
    "- 深度学习是机器学习的分支，是一种以人工神经网络为架构，对数据进行表征学习的方法。现已有数种常见深度学习网络架构，如全连接神经网络、卷积神经网络、深度置信网络和循环神经网络等。深度学习框架已被广泛应于与计算机视觉、语音识别、自然语言处理、音频识别等多个领域。\n",
    "\n",
    "### 3.2深度学习框架\n",
    "- 目前已有大量的人工智能应用框架，如TensorFlow、PyTorch、Caffe和MXNet等。\n",
    "- `本次实验中将使用TensorFlow深度学习框架来训练商品分类模型`。\n",
    "- TensorFlow是Google基于DistBelief研发的第二代人工智能学习系统，其名称来源于本身的运行原理。TensorFlow是将复杂的数据结构传输至人工智能神经网络中进行分析和处理的系统，有着众多的优点如灵活可扩展、运算性能强、支持多语言、支持多平台和提供强大的研究实验。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa44619",
   "metadata": {},
   "source": [
    "## 4目标检测算法\n",
    "\n",
    "图像分类模型可以将图像划分为单个类别，通常对应于图像中最突出的物体。但是现实世界的很多图片通常包含不只一个物体，此时如果使用图像分类模型为图像分配单一的标签并不准确。\n",
    "\n",
    "### 4.1目标检测\n",
    "- 对于这样的情况，就需要目标检测模型。目标检测模型可以识别一张图片的多个物体，并可以定位出不同物体（给出边界框）。\n",
    "- 目标检测被应用在许多场景，如无人驾驶和安防系统等。\n",
    "- 传统目标检测算法（如帧差法、Hough变换、光流法等）受到很多外在条件的限制。如当样本量较大时，最优阈值的计算效率太低，灰色信息容易被噪点污染，导致结果准确度低。\n",
    "- 随着卷积神经网络的广泛使用，许多目标检测算法与卷积神经网络结合起来。\n",
    "\n",
    "### 4.2目标检测算法\n",
    "- 根据目标检测算法的工作流程，可以将目标检测算法分为双步法（Two Stage）和单步法（One Stage）。\n",
    "  - 双步法\n",
    "    - 双步法的主要思路是先通过启发式方法或CNN网络产生一系列稀疏的候选框，然后对这些候选框进行分类或者回归。双步法的优势是准确度高，但是运行速度较慢。双步法的代表算法有R-CNN、Fast R-CNN、Faster R-CNN等。\n",
    "  - 单步法\n",
    "    - 单步法的主要思路是均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同尺寸和长宽比，利用CNN提取特征后，直接在提取的特征上进行分类或者回归，整个过程只需要一步，所以单步法的优势是速度快，但是均匀的密集采样的一个主要缺点是训练比较困难，这导致模型准确度较低。单步法的代表算法有Yolo和SSD等。在后续的模型训练中将会使用Yolo算法来实现目标检测。 \n",
    "  - Yolov3\n",
    "    - YOLO，是You Only Look Once的缩写，一种基于深度卷积神经网络的物体检测算法，YOLO v3是YOLO的第3个版本，具有检测速度快、背景误检率低、通用性强等优点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fbebb",
   "metadata": {},
   "source": [
    "## 5模型评估\n",
    "\n",
    "### 5.1模型评估指标\n",
    "- 通常需要定义性能指标用于评价模型的好坏，当然使用不同的性能指标对模型进行评价往往会有不同的结果，也就是说模型的好坏是“相对”的，什么样的模型好的，不仅取决于算法和数据，还决定于任务需求。因此，选取一个合理的模型评价指标是非常有必要的。\n",
    "- 性能评估的几个重要参数有精确度，精确度和召回率。在二元分类中，精确度和召回率是一个简单直观的统计量，但在目标检测中，物体检测模型的输出是非结构化的，事先并无法得知输出物体的数量、位置、大小等。\n",
    "- 物体检测的评价算法稍微复杂，对具体的某个物体来讲，我们可以使用 IOU (交并比)，即模型所预测的检测框和真实(ground truth)的检测框的交集和并集之间的比例，来量化贴和程度。\n",
    "<img style=\"float: center;\" width = \"200\" height = \"100\" src=\"./tmp/image/图片1.png\">\n",
    "\n",
    "**loU**\n",
    "- 使用loU看检测是否正确需要设定一个阈值，最常用的阈值是0.5，即如果loU>0.5，则认为是真实的检测(true detection)，否则认为是错误的检测(false detection)。\n",
    "- 通过模型计算可以得到的每个检测框(置信度阈值后)的loU值。用计算出的loU值与设定的loU阈值(如0.5)比较，就可以计算出每个图像中每个类的正确检测次数(A)。\n",
    "- 对于每个图像，我们都知道每个图像的真实目标信息,因此也知道了该图像中给定类别的实际目标(B)的数量，则可以使用(A/B)来评价该类模型的精度，也就是召回率（recall）。\n",
    "\n",
    "**mAP**\n",
    "- 一个常用的用于评价模型好坏的综合指标：均值平均精度，即mAP。mAP用于反应模型在给定所有的类别上表现的好坏程度。\n",
    "  - 其中代表P（Precision）精确率。\n",
    "  - AP（Average precision）单类标签平均（各个召回率中最大精确率的平均数）的精确率。\n",
    "  - mAP(Mean Average Precision)所有类标签的平均精确率。\n",
    "- 可以简单理解为以下公式：\n",
    "  - mAP = 所有类别的平均精度求和后除以所有类别，即数据集中所有类的平均精度的平均值。\n",
    "- 可以认为在测试集数据范围内，mAP越高，模型的表现越好。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b870e0",
   "metadata": {},
   "source": [
    "## 6 模型部署\n",
    "- 模型部署又称为模型发布，建立模型本身并不是机器学习的目标，虽然模型使数据背后隐藏的信息和知识显现出来，但机器学习的根本目标是将信息和知识以某种方式组织和呈现出来，并用来改善运营和提高效率。\n",
    "- 在实际的机器学习工作中，根据不同的业务需求，模型部署的具体工作可能简单到提交机器学习报告，也可能复杂到将模型集成到公司的核心运营系统中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda8c29-fcc2-4c41-80f6-1e9cebf5c42f",
   "metadata": {},
   "source": [
    "## 任务实施"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346b532",
   "metadata": {},
   "source": [
    "\n",
    "## 1 搭建实验环境\n",
    "\n",
    "### 1.1 检查项目地址\n",
    "BASE_PATH用于保存当前根目录地址，通过下面常用搭配可以快速获取\n",
    "```python  \n",
    "os.path.dirname(os.path.abspath('__file__'))\n",
    "```\n",
    "其他文件或文件夹位置都可以基于这个根目录得到，因此可以通过该方法实现动态地址，增强代码的兼容性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe75dfc-296e-4ad6-a93c-d6a323267759",
   "metadata": {},
   "source": [
    "**将任务路径更改到`train`目录下**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e77750-8d48-497d-ae49-af41e4d72f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/jovyan/yolo-flask-vue/train'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_PATH = os.path.dirname(os.path.abspath('__file__')) #常用搭配，显示当前路径\n",
    "print(BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da7ca9",
   "metadata": {},
   "source": [
    "### 1.2 目录结构介绍\n",
    "\n",
    "此部分将对`train`文件夹内容进行详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce6971",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" width = \"300\" height = \"100\" src=\"./tmp/image/目录结构.jpg\">\n",
    "\n",
    "**cfgs:** 用于存放模型配置文件\n",
    "\n",
    "**ckpts:** 用于存放训练生成的权重文件\n",
    "\n",
    "**core：** 用于存放核心代码文件\n",
    "\n",
    "**data：**\t用于存放数据相关文件\n",
    "\n",
    "**tmp ：** 用于临时存放文件目录\n",
    "\n",
    "**config.py：**\t超参数配置文件\n",
    "\n",
    "**convert_xml.py；**\t数据清单生成工具\n",
    "\n",
    "**detector.py\t：** 模型测试工具\n",
    "\n",
    "**requirements.txt：** 项目环境依赖清单\n",
    "\n",
    "**train.py：**\t模型训练工具\n",
    "\n",
    "**yolov3_tiny_mAP-0.7465.h5：** yolo3_tiny加载权重文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556beb37",
   "metadata": {},
   "source": [
    "## 2 依赖环境安装\n",
    "为避免安装依赖包过程出现安装失败的问题，需要先运行以下代码升级pip包。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57678c2",
   "metadata": {},
   "source": [
    "### 2.1 更新pip版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d15ed0",
   "metadata": {},
   "source": [
    "### 2.2 安装项目依赖环境\n",
    "\n",
    "依赖环境包括：\n",
    "- tensorflow-cpu==2.1 \n",
    "- easydict\n",
    "- pyyaml      \n",
    "- opencv-python   \n",
    "- h5py==2.10.0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ebe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -r requirements.txt -i https://pypi.douban.com/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2772b7c",
   "metadata": {},
   "source": [
    "## 3. 数据集的准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d2f7",
   "metadata": {},
   "source": [
    "### 3.1 数据集介绍\n",
    "本次实验使用的数据集包含：\n",
    "- 足球（football）\n",
    "- 篮球（basketball）\n",
    "- 甜甜圈（donut）\n",
    "- 橘子汁（orange_juice）\n",
    "- 薯片（potato_chip）\n",
    "\n",
    "### 3.2 配置识别物体的标签\n",
    "<font color = 'red' size=3>动手练习1</font>\n",
    "\n",
    "在以下代码中`<>`处填写缺失的参数，实现配置物体的标签：\n",
    "\n",
    "\n",
    "- 案例中目标物体为5类，包括足球（football），篮球（basketball），甜甜圈（donut），橘子汁（orange_juice），薯片（potato_chip）。请在`<1>`内配置物体标签。\n",
    "\n",
    "- 值得注意的是，为提升训练效率，训练过程中将使用标签的数字id（通过标签顺序确定id）而不是具体名称。\n",
    "  在训练结束后再根据标签顺序进行还原，因此所有涉及配置标签的过程请注意统一标签顺序，以防结果错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf28893",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = <1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344698ef-de3f-44d3-951b-216fa869e512",
   "metadata": {},
   "source": [
    "执行以下代码，输出为`['football', 'basketball', 'donut', 'orange_juice', 'potato_chip']`则填写正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81f693-fee4-49c0-8f27-0d6be94378a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a086475",
   "metadata": {},
   "source": [
    "### 3.2 提取图片路径并随机化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516cbec",
   "metadata": {},
   "source": [
    "<font color = 'red' size=3>动手练习2</font>\n",
    "\n",
    "在以下代码中`<>`处填写缺失的参数，实现对图片路径的随机化：\n",
    "- 请在`<1>`处配置图片文件夹地址，项目所使用的图片文件夹位于`./data/supermarket/img`\n",
    "- 请在`<2>`处使用random.shuffle()函数对图片进行随机化\n",
    "  - 随机化的目的是为后续划分训练数据集和测试数据集时，各类别的图片能够均匀分布在训练数据集和测试数据集上。如果直接使用有序排列的图片路径，将导致划分后的训练数据集和测试数据集内各标签比例严重失衡。\n",
    "  - random.shuffle(x)\n",
    "    - x为要随机化的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "INPUT_DIR= <1>\n",
    "\n",
    "paths = []\n",
    "for path in (os.path.join(p, name) for p, _, names in os.walk(INPUT_DIR) for name in names):\n",
    "    paths.append(path)\n",
    "random.shuffle(<2>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72884cad-db91-4859-80eb-a7772b1b621c",
   "metadata": {},
   "source": [
    "执行以下代码，输出为`250`则填写正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7096bb6-0c4e-4f81-b250-2b7f96785324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93237db",
   "metadata": {},
   "source": [
    "### 3.3 设置测试集划分比例\n",
    "\n",
    "模型训练过程是训练加测试不断迭代的过程，我们需要按照设定的比例将图片数据集随机划分为训练数据集和测试数据集（即使用模型评估方法-留出法，留出法将测试数据集和训练数据集完全分开，训练集数据用来训练算法生成模型，测试数据集通过模型来预测结果并与已知的结果进行比较，最终评估算法模型的准确度）。\n",
    "\n",
    "因此清单文件会被分为训练图片与标注文件清单和测试图片与标注文件清单，这样就可以在不移动文件的情况下实现数据的划分。\n",
    "\n",
    "<font color = 'red' size=3>动手练习3</font>\n",
    "\n",
    "在以下代码中`<1>`处填写缺失的参数：\n",
    "\n",
    "- 设置划分比例\n",
    "  - 通常需要在开始构建模型之前把数据集进行划分，将单个数据集拆分为一个训练集和一个测试集，比例一般为8:2，即vp的值可以设置为0.2。\n",
    "\n",
    "- 根据比例计算划分界限\n",
    "  - 根据划分比例（vp）计算出划分界限，即根据数据集的图片数量乘上划分比例来动态确定在第几张图片的位置进行划分能按比例将整个数据集分为两份（得到的结果需要舍弃小数进行取整）。\n",
    "  - 可能使用到的函数：round()取整函数，len()数量统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af75cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp =  <1>       #设置划分比例\n",
    "mid = int(vp*len(paths))       #根据比例确定划分界限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6377e0-9874-4d80-8b23-1ff912f77d07",
   "metadata": {},
   "source": [
    "执行以下代码，输出为`50`则填写正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094719a-3a80-42a5-a9d1-584bb6ace98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d12d40",
   "metadata": {},
   "source": [
    "### 3.4 设置xml信息提取函数\n",
    "\n",
    "xml文件格式统一容易读取，但存在大量无用的冗余信息。同时，tensorflow要求训练数据标注信息统一汇总在txt文件中。\n",
    "\n",
    "因此我们编写函数对xml文件信息进行提取，制作汇总训练需要的关键信息（即图片地址、标签id、标注框坐标信息）的txt文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xml(path,img_path):\n",
    "    result = img_path\n",
    "    for line in open(path):\n",
    "        if '<name>' in line:\n",
    "            for i in range(len(labels)):\n",
    "                if labels[i] in line:\n",
    "                    labelid = str(i)\n",
    "                    break\n",
    "        if '<xmin>' in line:\n",
    "            begin = line.find('<xmin>')\n",
    "            end = line.find('</xmin>')\n",
    "            xmin = line[begin+6:end]\n",
    "        if '<ymin>' in line:\n",
    "            begin = line.find('<ymin>')\n",
    "            end = line.find('</ymin>')\n",
    "            ymin = line[begin+6:end]\n",
    "        if '<xmax>' in line:\n",
    "            begin = line.find('<xmax>')\n",
    "            end = line.find('</xmax>')\n",
    "            xmax = line[begin+6:end]\n",
    "        if '<ymax>' in line:\n",
    "            begin = line.find('<ymax>')\n",
    "            end = line.find('</ymax>')\n",
    "            ymax = line[begin+6:end]\n",
    "            result = result+' '+xmin+','+ymin+','+xmax+','+ymax+','+labelid\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd5779",
   "metadata": {},
   "source": [
    "### 3.5 生成训练数据集\n",
    "过程中会根据文件名后缀来判断是否为图片文件，将过滤非图片文件。当目标为图片文件时，通过提取函数提取同名xml文件信息进行数据转换。\n",
    "\n",
    "#### <font color = 'red' size=3>动手练习4</font>\n",
    "\n",
    "在以下代码中`<>`处填写缺失的参数，实现训练数据集生成：\n",
    "\n",
    "- 在`<1>`处设置所生成的训练数据集地址\n",
    "  - 本项目统一将生成的训练数据集清单存放于`./data/train.txt`处，也可使用`BASE_PATH+'/data/train.txt'`的方式生成动态地址\n",
    "- 在`<2>`处划分训练数据部分\n",
    "  - `mid`变量已经确定了数据集划分的界限，使用切片法即可划分数据集，使用切片[mid:]选取80%的数据为训练集\n",
    "- 在`<3>`处补全xml文件夹路径\n",
    "  - 使用动态地址生成xml文件夹路径，与`<3>`后方的xml文件名组成完整的xml文件地址。\n",
    "  \n",
    "\n",
    "执行完成后将在data文件夹下生成train.txt文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain = open(<1>,'w')\n",
    "\n",
    "for img_path in paths[<2>]:\n",
    "    #print(img_path)\n",
    "    filename = img_path.split('/')[-1]\n",
    "    pd = filename.split('.')[-1]\n",
    "    if pd not in (\"jpg\", \"png\", \"jpeg\"):\n",
    "        continue\n",
    "\n",
    "    path = <3>+filename.split('.')[0]+'.xml'\n",
    "    \n",
    "    ftrain.write(extract_xml(path,img_path)+'\\n')\n",
    "\n",
    "ftrain.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684677ad-2b2c-458f-acdf-461ace134120",
   "metadata": {},
   "source": [
    "执行以下代码，输出为`200`则填写正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e937dc-9900-48af-bb98-0400d64ebe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_PATH+'/data/train.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46499a0b",
   "metadata": {},
   "source": [
    "### 3.6 生成测试数据集\n",
    "\n",
    "测试数据集生成过程与训练数据集类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779af671",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftest = open(BASE_PATH+'/data/test.txt','w')\n",
    "\n",
    "for img_path in paths[0:mid]:\n",
    "    filename = img_path.split('/')[-1]\n",
    "    pd = filename.split('.')[-1]\n",
    "    if pd not in (\"jpg\", \"png\", \"jpeg\"):\n",
    "        continue\n",
    "    path = BASE_PATH+'/data/supermarket/outputs/'+filename.split('.')[0]+'.xml'\n",
    "    \n",
    "    ftest.write(extract_xml(path,img_path)+'\\n')\n",
    "\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05908f",
   "metadata": {},
   "source": [
    "### 3.7 查看生成结果\n",
    "\n",
    "执行完成后将在`train`目录`data`文件夹下生成`train.txt`与`test.txt`文件。`train.txt`内容如图所示：\n",
    "<img style=\"float: left;\" width = \"600\" height = \"100\" src=\"./tmp/image/traintxt.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48331e2",
   "metadata": {},
   "source": [
    "## 4.根据数据集训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2276066",
   "metadata": {},
   "source": [
    "### 4.1 查看参数配置文件\n",
    "\n",
    "查看根目录下的参数配置文件config.py，此参数配置文件汇集了数据划分、数据标签、训练、预训练权重和测试相关的参数设置，能够帮助用户只使用一个文件就能控制整个项目的具体实现。\n",
    "[config.py](./train/config.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a2eea7",
   "metadata": {},
   "source": [
    "### 4.2 根据需求修改参数配置文件 (模型训练部分)\n",
    "**训练相关文件路径**\n",
    "   - 1)__C.TRAIN.NAME_PATH 标签配置文件的地址\n",
    "   - 2)__C.TRAIN.NUM_CLASSES 标签类别数\n",
    "   - 3)__C.TRAIN.TRAIN_ANNO_PATH 训练数据清单的地址\n",
    "   - 4)__C.TRAIN.TEST_ANNO_PATH 测试数据清单的地址\n",
    "   - 5)__C.TRAIN.YAML_PATH 模型网络参数配置文件的地址\n",
    "   \n",
    "**训练过程所需数值**\n",
    "   - 6)__C.TRAIN.LEARN_RATE_INIT 初始学习率\n",
    "   - 7)__C.TRAIN.LEARN_RATE_END 最终学习率\n",
    "   - 8)__C.TRAIN.WARMUP_LEARN_RATE 预热最大学习率\n",
    "   - 9)__C.TRAIN.WARMUP_EPOCHS 模型预热训练次数\n",
    "   - 10)__C.TRAIN.EPOCHS 模型最大训练次数\n",
    "   - 11)__C.TRAIN.BATCH_SIZE 设置批处理图片数量\n",
    "   \n",
    "**训练完成存储路径**\n",
    " - 12)__C.TRAIN.SAVE_NAME 模型权重文件保存命名格式\n",
    " - 13)__C.TRAIN.SAVE_WEIGHT_PATH 模型权重文件保存路径\n",
    " - 14)__C.TRAIN.INIT_WEIGHT_PATH 预训练权重的地址\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5e10c",
   "metadata": {},
   "source": [
    "- 1)填写标签配置文件存放地址（__C.TRAIN.NAME_PATH）：\n",
    "  - 此文件地址对应标注文件转换与数据集划分中步骤二的supermarket.name文件。\n",
    "- 2)填写标签类别数（__C.TRAIN.NUM_CLASSES）：\n",
    "  - 根据项目的目标物体的数量填写。\n",
    "- 3)填写训练数据清单地址（__C.TRAIN.TRAIN_ANNO_PATH）：\n",
    "  - 此清单文件用于训练过程中为模型提供训练数据。\n",
    "  - 文件地址对应标注文件转换与数据集划分中步骤六生成的训练数据集的标注信息文件。\n",
    "- 4)填写测试数据清单地址（__C.TRAIN.TEST_ANNO_PATH）：\n",
    "  - 此清单文件用于模型泛化能力测试过程，模型将根据此数据集测试得到的mAP指标结果来评价当前权重的优劣。\n",
    "  - 文件地址对应标注文件转换与数据集划分中步骤七生成的测试数据集的标注信息文件。\n",
    "- 5)填写模型网络参数配置文件的地址（__C.TRAIN.YAML_PATH）：\n",
    "  - 本项目提供多种不同的yolo模型，配置文件均存放于cfgs文件夹下，读者可根据模型特点和实际需求选择合适的模型网络配置文件。\n",
    "  - 如常用的yolov3、yolov4模型，在识别准确度上表现较好，但由于模型复杂，对硬件算力要求更高，在不使用优化方法的情况下，两者在移动端设备的运行效率不尽如人意。\n",
    "  - 对于简化版本yolov3_tiny和yolov4_tiny，两者虽在精度上弱于原版，但更适合边缘端设备，有更高的运行速度和不错的识别效果。其中yolov3_tiny速度更快于yolov4_tiny，但在精度上稍弱于后者。\n",
    "    \n",
    "    \n",
    "**训练过程所需数值**\n",
    "- 6)填写初始学习率（__C.TRAIN.LEARN_RATE_INIT）：\n",
    "  - 为模型训练设置初始学习率，学习率的设置通常需要根据经验并结合实际情况进行调整，由于此次案例为微调训练，建议设置学习率为10的负5次方（1e-5）。\n",
    "- 7)填写学习率调整终点（__C.TRAIN.LEARN_RATE_END）：\n",
    "  - 学习率变化终点，学习率会随着模型训练迭代次数的增加逐步降低为设定的终点值。建议设置为10的负6次方（1e-6）。\n",
    "- 8)填写预热最大学习率（__C.TRAIN.WARMUP_LEARN_RATE）：\n",
    "  - 设置预热训练的最大学习率。预热训练可以看成是一个较为完备的参数初始化过程，即在模型训练的预热阶段使用较小的学习率，尽量使网络不要因为不好的初始化造成模型波动而无法训练收敛。\n",
    "  \n",
    "  使用原因：    \n",
    "            初始训练过程,模型的权重(weights)是随机初始化的，使用较大的学习率可能带来模型的不稳定(振荡)。     \n",
    "            在预热的小学习率下，模型可以慢慢趋于稳定,等模型相对稳定后再选择预先设置的学习率进行训练。     \n",
    "            同时，预热训练能够使模型收敛速度变得更快，模型效果更佳。   \n",
    "        \n",
    "- 9)填写预热训练迭代次数（__C.TRAIN.WARMUP_EPOCHS）：\n",
    "  - 设置预热训练的迭代次数。参数8）与9）共同决定预热训练过程，即初始学习率将从0经过设定的次数逐渐升至设置的预热最大学习率，等模型相对稳定后再选择预先设置的初始学习率进行训练,使得模型收敛速度变得更快，模型效果更佳。\n",
    "- 10)填写模型最大训练次数（__C.TRAIN.EPOCHS ）：\n",
    "  - 模型训练将会根据这个最大训练次数自动分为两个阶段进行训练。\n",
    "  - 第一个阶段占最大训练次数的五分之二，此阶段将专注于训练最后的检测部分，即只训练最后的分类与回归层。\n",
    "  - 第二个阶段占最大训练次数的五分之三，此阶段为对整个模型进行训练。\n",
    "- 11)设置批处理图片数量（__C.TRAIN.BATCH_SIZE）：\n",
    "  - 设定每次训练传入模型的图片张数。在合理范围内增大批处理数量有利于提高内存利用率，帮助模型快速收敛，但需根据硬件条件设置，以免超出内存上限导致代码运行失败。\n",
    "    \n",
    "  \n",
    "**训练完成存储路径**\n",
    "- 12)模型权重文件保存命名格式（__C.TRAIN.SAVE_NAME）：\n",
    "  - 在模型训练过程中，会在每次迭代后测试当前权重的泛化能力，使用mAP作为量化指标。\n",
    "  - 当mAP值较先前模型有所提升，则根据保存命名格式保存当前模型权重文件。\n",
    "- 13)模型权重文件保存路径（__C.TRAIN.SAVE_WEIGHT_PATH）：\n",
    "  - 代码将会在该设定的位置下自动根据模型类别，训练时间建立文件夹，保存训练生成的模型权重文件。\n",
    "- 14)填写预训练权重存放地址（__C.TRAIN.INIT_WEIGHT_PATH）：\n",
    "  - 选择并填写合适的预训练权重。配套资料中在项目文件根目录提供了预训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd18bba",
   "metadata": {},
   "source": [
    "### 4.3 参数作用流程总结\n",
    "**数据标签**    \n",
    "- `参数1）（__C.TRAIN.NAME_PATH）`标签配置文件与`参数2）（__C.TRAIN.NUM_CLASSES）`标签类别数为模型提供了具体的标签信息。    \n",
    "\n",
    "**模型构建**    \n",
    "- 在启动训练代码时，首先载入`参数5）（__C.TRAIN.YAML_PATH）`模型网络参数配置文件，构建神经网络。   \n",
    "\n",
    "**预训练加载**    \n",
    "- 如果`参数14）（__C.TRAIN.INIT_WEIGHT_PATH）`有配置预训练模型，则加载预训练模型权重，无则从零开始训练模型。   \n",
    "\n",
    "**数据载入**    \n",
    "- 在训练过程，模型将调用`参数3）（__C.TRAIN.TRAIN_ANNO_PATH）`训练数据清单为模型输入训练数据，每次根据`参数11）（__C.TRAIN.BATCH_SIZE）`批处理设定值传入多张图片，完整处理完全部图片称为一次迭代。\n",
    "\n",
    "**预热训练**\n",
    "- 由于神经网络在刚开始训练的时候是非常不稳定的，因此刚开始的学习率应当设置得很低，这样可以保证网络能够具有良好的收敛性，这里采用以较低学习率逐渐增大至较高学习率的方式实现网络训练的“热身”阶段。\n",
    "- 此过程根据`参数8）（__C.TRAIN.WARMUP_LEARN_RATE）`预热最大学习率和`9）（__C.TRAIN.WARMUP_EPOCHS）`预热训练迭代次数执行预热过程。\n",
    "\n",
    "**开始训练**\n",
    "- 完成后，模型以`参数6）（__C.TRAIN.LEARN_RATE_INIT）`初始学习率进行正式训练。一般使用较大的初始学习率来加快模型收敛进度，但训练的最终目标是尽可能使网络训练的损失最小，那么一直使用较高学习率是不合适的，因为它会使得权重的梯度一直来回震荡，很难使训练的损失值达到全局最低谷。\n",
    "- 因此，学习率会随着训练迭代次数的增加而逐步减小到人为设置的最低值，即`参数7）（__C.TRAIN.LEARN_RATE_END）`设定的学习率调整终点。此过程将经过两个阶段，总计训练迭代次数总和为`参数10）（__C.TRAIN.EPOCHS ）`设定的最大训练次数。\n",
    "\n",
    "**实时评估**\n",
    "- 每当每次迭代完成后都会自动调用`参数4）（__C.TRAIN.TEST_ANNO_PATH）`测试清单的数据测试当前模型的泛化能力，以平均精确率mAP为指标衡量模型对于当前测试集的表现，如果现有模型表现优于之前的模型，则会根据`参数12）（__C.TRAIN.SAVE_NAME）`命名格式自动保存当前模型到`参数13）（__C.TRAIN.SAVE_WEIGHT_PATH）`指定的文件夹下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52efa2",
   "metadata": {},
   "source": [
    "### 4.3 执行训练代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f3a59",
   "metadata": {},
   "source": [
    "请运行下方代码进行模型训练，训练过程将根据配置文件config.py中设置的参数进行，训练时终端界面将实时输出训练进度与损失参数信息。\n",
    "\n",
    "**注意，执行训练脚本花费的时间比较长，后续任务2会针对训练进行讲解，此处可暂时略过**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2fef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54c9e4",
   "metadata": {},
   "source": [
    "## 5. 使用模型预测图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b16b0e",
   "metadata": {},
   "source": [
    "### 5.1 根据需求修改参数配置文件 (模型评估部分)\n",
    "- 1）__C.EVAL.TEST_WEIGHT_PATH 用于评估权重地址\n",
    "- 2）__C.EVAL.IMG_PATH 用于评估的图片/文件夹/视频地址\n",
    "- 3）__C.EVAL.SAVE_PATH预测结果保存位置\n",
    "\n",
    "- 1）填写评估权重地址（__C.EVAL.TEST_WEIGHT_PATH）：\n",
    "  - 此地址为用于评估的权重地址\n",
    "- 2）填写用于评估的图片/文件夹/视频地址（__C.EVAL.IMG_PATH）：\n",
    "  - 选择需要进行评估的内容，支持填入图片地址，文件夹地址或视频文件地址。\n",
    "- 3）填写结果保存位置（__C.EVAL.SAVE_PATH）：\n",
    "  - 模型处理后生成的文件都将放入该地址下。\n",
    "\n",
    "\n",
    "\n",
    "### 5.2 执行预测代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 detector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b17d6",
   "metadata": {},
   "source": [
    "### 5.3 参数作用流程总结\n",
    "**模型前向传播进行图片预测**\n",
    "- 模型预测代码将载入`参数1（__C.EVAL.TEST_WEIGHT_PATH）`所指定的权重文件，读入`参数2（__C.EVAL.IMG_PATH）`所指定位置的数据并进行进行前向传播，在设定的`参数3（__C.EVAL.SAVE_PATH）`位置生成预测结果。\n",
    "\n",
    "**输出结果**\n",
    "- 在代码运行完成后，`./data/supermarket/detection`文件夹内将生成所有测试集图片的预测结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5dc24c",
   "metadata": {},
   "source": [
    "### 5.4 查看输出结果\n",
    "进入`./data/supermarket/detection`文件夹查看预测结果。随机打开其中一个图片，如下图所示：\n",
    "\n",
    "<img style=\"float: left;\" width = \"800\" height = \"100\" src=\"./tmp/image/预测效果.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286255c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
